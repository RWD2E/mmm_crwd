{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# where clause for identifing pregnancy events using ICD codes\n",
    "def dx_where_clause(icd_lst:list,alias=''):\n",
    "    '''\n",
    "    sql where clause for cohort selection based on ICD code list\n",
    "    '''\n",
    "    if alias is not '':\n",
    "        alias += '.'\n",
    "    icd_quote = []\n",
    "    for code in icd_lst:\n",
    "        icd_quote.append(\"'\"+ code +\"'\")\n",
    "    icd_quote_str = \",\".join(icd_quote)\n",
    "    sql_str = \"substring_index(upper(\"+ alias +\"conditioncode.standard.id),'.',1) in (\" + icd_quote_str +\")\"\n",
    "    return sql_str \n",
    "\n",
    "preg_icd = [str(x) for x in list(range(630,679,1))]\n",
    "preg_icd.extend(['V22','V23','V28','Z33','Z34','Z35','Z36','Z37','Z38','Z3A','O9A'])\n",
    "preg_icd.extend(['O0' + str(x) for x in list(range(0,9,1))])\n",
    "preg_icd.extend(['O' + str(x) for x in list(range(10,99,1))])\n",
    "preg_where_clause = dx_where_clause(preg_icd,\"cond\") \n",
    "preg_where_clause"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"USE real_world_data_jun_2022\")\n",
    "preg_pt_init = spark.sql('''\n",
    "    select distinct\n",
    "           cond.personid,\n",
    "           to_date(demo.birthdate) as dob,\n",
    "           to_date(demo.dateofdeath) as dod,\n",
    "           demo.deceased as deceased_ind,\n",
    "           demo.gender.standard.id as gender,\n",
    "           demo.races[0].standard.primaryDisplay as race,\n",
    "           demo.ethnicities[0].standard.primaryDisplay as ethnicity,\n",
    "           cond.encounterid,\n",
    "           to_date(cond.effectivedate) as dx_date,\n",
    "           cast(round(datediff(to_date(cond.effectivedate),to_date(demo.birthdate))/365.25) as int) as age_at_dx,\n",
    "           enc.classification.standard.id as enc_type,\n",
    "           to_date(enc.actualarrivaldate) as admit_date,\n",
    "           cast(round(datediff(to_date(enc.actualarrivaldate),to_date(demo.birthdate))/365.25) as int) as age_at_enc,\n",
    "           enc.readmission,\n",
    "           to_date(enc.dischargedate) as discharge_date,\n",
    "           enc.tenant as enc_tenant,\n",
    "           tnt.bed_size,\n",
    "           tnt.speciality,\n",
    "           tnt.segment\n",
    "    from condition cond\n",
    "    join encounter enc on cond.encounterid = enc.encounterid\n",
    "    join demographics demo on cond.personid = demo.personid\n",
    "    left join tenant_attributes tnt on enc.tenant = tnt.tenant \n",
    "    where ''' + preg_where_clause\n",
    ").cache()\n",
    "preg_pt_init.createOrReplaceTempView(\"preg_pt_init\")\n",
    "preg_pt_init.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "def pt_freq_qry(df,stratified_by,n_way=1):\n",
    "    '''\n",
    "    generate total patient counts for each stratified variables\n",
    "    '''\n",
    "    sql_str_lst = []\n",
    "    # overall count\n",
    "    sql_str_lst.append(\"select 'total' as summ_var,'N' as summ_cat, count(distinct personid) as pat_cnt from \" + df \n",
    "                       + where_clause)\n",
    "    # 1-way summary\n",
    "    for var_str in stratified_by:\n",
    "        sql_str_lst.append(\n",
    "            \"select 'by_\" + var_str +\"' as summ_var,\" \n",
    "            + \"cast(\" + var_str +\" as string) as summ_cat,\"\n",
    "            + \"count(distinct personid) as pat_cnt \"\n",
    "            + \"from \"+ df + \" group by \"+ var_str\n",
    "        )\n",
    "        \n",
    "    # n-way summary\n",
    "    if n_way > 1:\n",
    "        for L in range(2,n_way+1,1):\n",
    "            for var_str_comb in itertools.combinations(stratified_by, L):\n",
    "                var_str_concat_by_underline = \"_\".join(var_str_comb)\n",
    "                var_str_concat_by_pipe = \"||\".join(var_str_comb)\n",
    "                var_str_concat_by_comma = \",\".join(var_str_comb)\n",
    "                sql_str_lst.append(\n",
    "                    \"select 'by_\" + var_str_concat_by_underline +\"' as summ_var,\" \n",
    "                    + \"cast(\" + var_str_concat_by_pipe +\" as string) as summ_cat,\"\n",
    "                    + \"count(distinct personid) as pat_cnt \"\n",
    "                    + \"from \"+ df + \" group by \"+ var_str_concat_by_comma\n",
    "                )\n",
    "    \n",
    "    # union everything\n",
    "    sql_str = \" union \".join(sql_str_lst)\n",
    "    return(sql_str)\n",
    "\n",
    "stratified_by = [\n",
    "    'gender',\n",
    "    'race',\n",
    "    'ethnicity',\n",
    "    'segment',\n",
    "    'speciality',\n",
    "    'bed_size',\n",
    "    'deceased_ind'\n",
    "]\n",
    "get_pt_summ = pt_freq_qry('preg_pt_init',stratified_by,n_way=2)\n",
    "get_pt_summ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_pt_summ = pt_freq_qry(\n",
    "    'preg_pt_init',stratified_by,n_way=1\n",
    ")\n",
    "summ_stat_long = spark.sql(get_pt_summ).toPandas()\n",
    "summ_stat_long.to_csv('./data/summ_stat.csv')\n",
    "summ_stat_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"USE real_world_data_jun_2022\")\n",
    "preg_pt_12to55 = spark.sql('''\n",
    "    select * from preg_pt_init\n",
    "    where coalesce(dx_date,admit_date) between to_date('2010-01-01') and to_date('2022-12-31') and\n",
    "          coalesce(age_at_dx,age_at_enc) between 12 and 55\n",
    "''').cache()\n",
    "preg_pt_12to55.createOrReplaceTempView(\"preg_pt_12to55\")\n",
    "preg_pt_12to55.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_pt_summ = pt_freq_qry(\n",
    "    'preg_pt_12to55',stratified_by,n_way=1\n",
    ")\n",
    "summ_stat_long = spark.sql(get_pt_summ).toPandas()\n",
    "summ_stat_long.to_csv('./data/summ_stat_12to55.csv')\n",
    "summ_stat_long"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
